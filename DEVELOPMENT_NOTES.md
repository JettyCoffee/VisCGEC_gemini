# VisCGEC 开发记录文档

本文档记录了VisCGEC项目的主要开发历程、技术选择和性能优化过程。

## 1. 项目规划与设计

### 1.1 需求分析
- 目标：构建端到端的中文OCR文本纠错系统
- 主要挑战：OCR识别准确性、文本纠错质量、处理效率
- 应用场景：文档数字化、学术研究、实际业务场景

### 1.2 架构设计决策
- 采用流水线架构，拆分为独立模块
- 选择基于深度学习的OCR和文本纠错模型
- 设计可扩展的数据处理流程

### 1.3 性能评估历程
项目开发过程中持续进行性能评估，从初始的0.2776分逐步提升至0.5102分，主要改进阶段：
- 0.2776：初始BERT模型实现，基础OCR处理
- 0.4975：引入更优的OCR模型和初步纠错策略
- 0.4982：优化数据清洗流程，提升输入质量
- 0.5036：集成GOT-OCR模型，提高复杂场景识别能力
- 0.5051：优化PaddleOCR配置，提升基础识别准确率
- 0.5053：改进文本分句策略，增强上下文理解
- 0.5102：最终版本，优化prompt设计和模型集成策略

## 2. OCR引擎选择与优化

### 2.1 OCR引擎对比与选择历程
项目经历了多次OCR引擎迭代选择：

**早期阶段**：
- 初始使用基于BERT的简单OCR模型，限于资源约束，识别效果一般（评分约0.27）
- 测试了多种开源OCR方案，包括Tesseract、EasyOCR等

**中期发展**：
- 引入GOT-OCR模型，针对中文文档场景进行了优化（评分提升至0.49+）
- GOT-OCR在特定场景（如手写体、不规则排版）表现较好，但通用性存在挑战

**最终选择**：
- 最终采用PaddleOCR，兼顾了识别准确率、处理速度和易用性
- 在PaddleOCR基础上进行了定制化修改，特别优化了中文场景（评分达到0.51+）
- 保留了GOT-OCR作为特定场景的补充方案

### 2.2 PaddleOCR模型优化

#### 2.2.1 模型选择
经过性能测试，从PaddleOCR提供的多个模型中选择了以下配置：
```python
det_model_dir="models/PaddleOCR/ppstructure/inference/PP-OCRv5_server_det_infer"
rec_model_dir="models/PaddleOCR/ppstructure/inference/PP-OCRv5_server_rec_infer"
rec_char_dict_path="models/PaddleOCR/ppocr/utils/ppocrv5_dict.txt"
table_model_dir="models/PaddleOCR/ppstructure/inference/ch_ppstructure_mobile_v2.0_SLANet_infer"
```

主要优化点：
- 使用服务器端模型代替移动端模型，提高识别精度
- 使用PP-OCRv5版本，相比v3版本提升了约5%的识别准确率
- 定制中文字典，扩展特殊字符和专业术语的支持

#### 2.2.2 预测系统修改
对PaddleOCR的预测系统进行了定制化修改：
- 修改了`predict_system_enhanced.py`以优化处理流程
  - 该文件需放置在`models/PaddleOCR/ppstructure/`目录下
  - 主要修改：将表格识别结果统一转换为图像类型，避免表格结构识别错误
  - 核心代码修改：
    ```python
    for reg in layout_res:
        if reg["label"] == "table":   # 把任何 table 统统改成 figure
            reg["label"] = "figure"
    ```
- 调整了文本行合并策略，提高了复杂版面的识别效果
- 优化了检测框过滤逻辑，减少噪声检测

#### 2.2.3 并行处理优化
实现了多GPU并行处理机制：
- 使用ProcessPoolExecutor实现GPU级并行
- 使用ThreadPoolExecutor实现单GPU内的任务并行
- 自适应负载均衡，根据GPU数量动态分配任务

### 2.3 自定义字典配置
为提高中文识别准确率，定制了专用字典：
- 在`ppocrv5_dict.txt`中增加了常见中文错误对应字符
- 确保字典文件放置在正确路径：`models/PaddleOCR/ppocr/utils/ppocrv5_dict.txt`

## 3. 文本纠错模型选择

### 3.1 模型评估
评估了多种中文文本纠错模型：
- BERT-based模型：轻量但效果有限（初始阶段使用，评分约0.27-0.30）
- 传统规则+统计模型：速度快但准确率不足（评分约0.35-0.40）
- T5/BART类生成模型：在中小规模测试中表现较好（评分约0.42-0.45）
- GPT类大模型：效果最佳但资源消耗大且只能使用api调用（评分0.48+）

### 3.2 ChineseErrorCorrector2-7B优化
最终选择了ChineseErrorCorrector2-7B作为主要纠错模型：

#### 3.2.1 模型特性
- 基于LLaMA-2的中文优化版本
- 针对中文语法错误和OCR错误进行了特殊训练
- 7B参数量在单GPU上有较好的推理性能与效果平衡

#### 3.2.2 Prompt工程优化
对模型prompt进行了精细调优：
```python
self.prompt = "你是一个文本纠错专家，纠正输入句子中的语法、拼写、标点错误，并输出语义通顺的句子，输入句子为："
```

主要优化点：
- 明确角色定位（"文本纠错专家"）增强模型在特定任务的表现
- 明确纠错范围（"语法、拼写、标点错误"）提高纠错针对性
- 强调输出要求（"语义通顺"）确保纠错结果的自然流畅
- 简洁指令设计，避免冗长prompt导致的注意力分散

#### 3.2.3 基于Transformer的分句策略
为解决大模型上下文长度限制问题，实现了基于语义的分句策略：
- 使用chinese-roberta-wwm-ext模型进行语义化分句
- 考虑句子间语义连贯性，避免机械分割导致的上下文丢失
- 实验证明，分句处理后的纠错效果显著优于整段文本直接处理
- 分句策略使评分从0.5053提升到0.5102

## 4. 数据处理流程优化

### 4.1 图像预处理
- 实现了自适应对比度增强
- 添加了噪点消除和边缘增强
- 优化了文档图像的二值化处理

### 4.2 数据清洗策略
- 设计了基于置信度的文本过滤
- 实现了特殊字符规范化处理
- 添加了文本段落合并逻辑

### 4.3 基于Transformer的智能分句
针对大模型上下文长度限制，开发了智能分句机制：

#### 4.3.1 技术方案
- 使用chinese-roberta-wwm-ext作为分句模型
- 基于语义特征而非简单标点符号进行分句
- 保持句子上下文连贯性，避免语义割裂

#### 4.3.2 实现细节
- 对文本进行初步分割，得到候选句子
- 利用Transformer模型提取每个句子的语义向量
- 基于语义相似度判断句子间的关联强度
- 将语义相关性高的短句合并，确保上下文完整
- 控制最终句子长度不超过模型处理能力（约100-150字）

## 5. 系统集成与测试

### 5.1 流水线脚本设计
- 设计了自动化流水线脚本`pipeline.sh`
- 实现了日志记录和错误处理机制
- 支持单模块独立运行和完整流程执行

### 5.2 准确率评估
- 设计了多指标评估体系，基于标准校对指标
- 在标准测试集上进行了对比测试，记录不同版本性能：
  - 0.2776：初始版本基准性能
  - 0.4975：引入优化OCR模型后的提升
  - 0.4982：加入数据清洗策略后的改进
  - 0.5036：优化OCR引擎配置后的提升
  - 0.5051：改进表格识别处理后的性能
  - 0.5053：优化文本预处理后的效果
  - 0.5102：引入分句策略与prompt优化后的最终性能
- 持续优化模型配置，实现了超过84%的相对性能提升
